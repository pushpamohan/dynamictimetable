{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of movie_recommendation_using_ALS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "iHo-5TU53MMo",
        "weyPAayA3MM1"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushpamohan/dynamictimetable/blob/master/Copy_of_movie_recommendation_using_ALS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfMI01Yr3MKg",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this project, I will use an Alternating Least Squares (ALS) algorithm with Spark APIs to predict the ratings for the movies in [MovieLens Datasets](https://grouplens.org/datasets/movielens/latest/)\n",
        "\n",
        "## [Recommender system](https://en.wikipedia.org/wiki/Recommender_system)\n",
        "A recommendation system is basically an information filtering system that seeks to predict the \"rating\" or \"preference\" a user would give to an item. It is widely used in different internet / online business such as Amazon, Netflix, Spotify, or social media like Facebook and Youtube. By using recommender systems, those companies are able to provide better or more suited products/services/contents that are personalized to a user based on his/her historical consumer behaviors\n",
        "\n",
        "Recommender systems typically produce a list of recommendations through collaborative filtering or through content-based filtering\n",
        "\n",
        "This project will focus on collaborative filtering and use Alternating Least Squares (ALS) algorithm to make movie predictions\n",
        "\n",
        "\n",
        "## [Alternating Least Squares](https://endymecy.gitbooks.io/spark-ml-source-analysis/content/%E6%8E%A8%E8%8D%90/papers/Large-scale%20Parallel%20Collaborative%20Filtering%20the%20Netflix%20Prize.pdf)\n",
        "ALS is one of the low rank matrix approximation algorithms for collaborative filtering. ALS decomposes user-item matrix into two low rank matrixes: user matrix and item matrix. In collaborative filtering, users and products are described by a small set of latent factors that can be used to predict missing entries. And ALS algorithm learns these latent factors by matrix factorization\n",
        "\n",
        "\n",
        "## Data Sets\n",
        "I use [MovieLens Datasets](https://grouplens.org/datasets/movielens/latest/).\n",
        "This dataset (ml-latest.zip) describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 27753444 ratings and 1108997 tag applications across 58098 movies. These data were created by 283228 users between January 09, 1995 and September 26, 2018. This dataset was generated on September 26, 2018.\n",
        "\n",
        "Users were selected at random for inclusion. All selected users had rated at least 1 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
        "\n",
        "The data are contained in the files `genome-scores.csv`, `genome-tags.csv`, `links.csv`, `movies.csv`, `ratings.csv` and `tags.csv`.\n",
        "\n",
        "## Project Content\n",
        "1. Load Data\n",
        "2. Spark SQL and OLAP\n",
        "3. Spark ALS based approach for training model\n",
        "4. ALS Model Selection and Evaluation\n",
        "5. Model testing\n",
        "6. Make movie recommendation to myself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qLn-ouLC5rd",
        "colab_type": "code",
        "outputId": "dfe67399-4cfd-45e8-8bcb-5d902d11b10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=fa3cc36e017f11a6aaeea2b22190d24e2d77b20a9b091aa342e26ad74d595d0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-679b45a8c926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mGPUs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetGPUs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# XXX: only one GPU on Colab and isn’t guaranteed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprintm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m  \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcuPgQrI6R4J",
        "colab_type": "code",
        "outputId": "7d10b182-4883-428f-b886-8e2ae3d51b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "!curl -O http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip\n",
        "!cd ml-latest-small/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  955k  100  955k    0     0  3436k      0 --:--:-- --:--:-- --:--:-- 3436k\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmeHGYnfqYrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf Movielens\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkXoysSNqldH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd ../\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMXPwZ-v7MVH",
        "colab_type": "code",
        "outputId": "68d6043d-27e6-44d7-d387-abb7682f6adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ml-20m\tml-20m.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzYCfpKgdSvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u__v49Gr74NU",
        "colab_type": "code",
        "outputId": "2c5e62e7-0a6d-4069-f356-33e00f09a9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
            "\u001b[K     |████████████████████████████████| 215.6MB 97kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 38.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.3-py2.py3-none-any.whl size=215964963 sha256=7705250e5e1c717c72bfc92e2b92acae4d9758282a87a44945264dabc253ced7\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1_YJWoY3MKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\"\n",
        "# spark imports\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
        "from pyspark.sql.types import StringType, ArrayType\n",
        "from pyspark.mllib.recommendation import ALS\n",
        "\n",
        "# data science imports\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# visualization imports\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qp9GnU2rR99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export PATH=$SPARK_HOME/bin:$PATH\n",
        "!export PYSPARK_PYTHON=python3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_j6OHwD3MKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spark config\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"movie recommendation\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"96g\") \\\n",
        "    .config(\"spark.driver.memory\", \"96g\") \\\n",
        "    .config(\"spark.executor.memory\", \"8g\") \\\n",
        "    .config(\"spark.master\", \"local[12]\") \\\n",
        "    .getOrCreate()\n",
        "# get spark context\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX7UL2cr3MKx",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA7aOeqe3MKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies = spark.read.load(os.path.join('/content/ml-latest-small', 'movies.csv'), format='csv', header=True, inferSchema=True)\n",
        "ratings = spark.read.load(os.path.join('/content/ml-latest-small', 'ratings.csv'),format='csv', header=True, inferSchema=True)\n",
        "links = spark.read.load(os.path.join('/content/ml-latest-small','links.csv'), format='csv', header=True, inferSchema=True)\n",
        "tags = spark.read.load(os.path.join('/content/ml-latest-small','tags.csv'), format='csv', header=True, inferSchema=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F81d-AGBRSX",
        "colab_type": "code",
        "outputId": "f79ddaf1-a33e-4215-e445-4832626d10e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "# $example on$\n",
        "from numpy import array\n",
        "# $example off$\n",
        "\n",
        "from pyspark import SparkContext\n",
        "# $example on$\n",
        "from pyspark.mllib.clustering import BisectingKMeans\n",
        "# $example off$\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "   # sc = SparkContext(appName=\"PythonBisectingKMeansExample\")  # SparkContext\n",
        "\n",
        "    # $example on$\n",
        "    # Load and parse the data\n",
        "data = sc.textFile(\"/content/ml-latest-small/ratings.csv\")\n",
        "parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n",
        "\n",
        "    # Build the model (cluster the data)\n",
        "model = BisectingKMeans.train(parsedData, 3, maxIterations=5)\n",
        "\n",
        "    # Evaluate clustering\n",
        "cost = model.computeCost(parsedData)\n",
        "print(\"Bisecting K-means Cost = \" + str(cost))\n",
        "    # $example off$\n",
        "\n",
        "#    sc.stop()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c467966bef9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Build the model (cluster the data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBisectingKMeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsedData\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmaxIterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Evaluate clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/mllib/clustering.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, rdd, k, maxIterations, minDivisibleClusterSize, seed)\u001b[0m\n\u001b[1;32m    165\u001b[0m         java_model = callMLlibFunc(\n\u001b[1;32m    166\u001b[0m             \u001b[0;34m\"trainBisectingKMeans\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_to_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             k, maxIterations, minDivisibleClusterSize, seed)\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBisectingKMeansModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/mllib/common.py\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[0;34m(name, *args)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/mllib/common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[0;34m(sc, func, *args)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o244.trainBisectingKMeans.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 31, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/content/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/content/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/content/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/content/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-15-c467966bef9b>\", line 18, in <lambda>\n  File \"<ipython-input-15-c467966bef9b>\", line 18, in <listcomp>\nValueError: could not convert string to float: 'userId,movieId,rating,timestamp'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:390)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1337)\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1377)\n\tat org.apache.spark.mllib.clustering.BisectingKMeans.run(BisectingKMeans.scala:163)\n\tat org.apache.spark.mllib.clustering.BisectingKMeans.run(BisectingKMeans.scala:255)\n\tat org.apache.spark.mllib.clustering.BisectingKMeans.run(BisectingKMeans.scala:261)\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainBisectingKMeans(PythonMLLibAPI.scala:135)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/content/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/content/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/content/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/content/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-15-c467966bef9b>\", line 18, in <lambda>\n  File \"<ipython-input-15-c467966bef9b>\", line 18, in <listcomp>\nValueError: could not convert string to float: 'userId,movieId,rating,timestamp'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:390)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ppo8PjVFDR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Build the model (cluster the data)\n",
        "model = BisectingKMeans.train(train, 3, maxIterations=5)\n",
        "\n",
        "    # Evaluate clustering\n",
        "cost = model.computeCost(train)\n",
        "print(\"Bisecting K-means Cost = \" + str(cost))\n",
        "    # $example off$\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dRnMpSR3MK1",
        "colab_type": "text"
      },
      "source": [
        "### basic inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPMoN4RW3MK2",
        "colab_type": "code",
        "outputId": "6b7a8f6c-24ef-49e0-d732-03752112aaa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "movies.show(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGkoJPE43MK8",
        "colab_type": "code",
        "outputId": "7c9252ed-5bc7-45a1-dd58-27ae7ca780f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "ratings.show(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|      2|   3.5|1112486027|\n",
            "|     1|     29|   3.5|1112484676|\n",
            "|     1|     32|   3.5|1112484819|\n",
            "+------+-------+------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsUoD0133MLA",
        "colab_type": "code",
        "outputId": "c4e6b25d-01ee-4c7d-f610-81ae2c40d4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "links.show(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+------+\n",
            "|movieId|imdbId|tmdbId|\n",
            "+-------+------+------+\n",
            "|      1|114709|   862|\n",
            "|      2|113497|  8844|\n",
            "|      3|113228| 15602|\n",
            "+-------+------+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhMyVqAT3MLE",
        "colab_type": "code",
        "outputId": "a6f74b12-97a0-48b2-f260-50a74c59f84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "tags.show(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+-----------+----------+\n",
            "|userId|movieId|        tag| timestamp|\n",
            "+------+-------+-----------+----------+\n",
            "|    18|   4141|Mark Waters|1240597180|\n",
            "|    65|    208|  dark hero|1368150078|\n",
            "|    65|    353|  dark hero|1368150079|\n",
            "+------+-------+-----------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VwuN5Yx3MLH",
        "colab_type": "text"
      },
      "source": [
        "## Spark SQL and OLAP\n",
        "\n",
        "Below are the questions I'd like to ask:\n",
        "1. What are the ratings?\n",
        "2. What is minimum number of ratings per user and minimum number of ratings per movie?\n",
        "3. How many movies are rated by only one user?\n",
        "4. What is the total number of users in the data sets?\n",
        "5. What is the total number of movies in the data sets?\n",
        "6. How many movies are rated by users? List movies not rated yet?\n",
        "7. List all movie genres\n",
        "8. Find out the number of movies for each category\n",
        "9. Calculate the total rating count for every movie\n",
        "10. Get a count plot for each rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDhO4xI_3MLJ",
        "colab_type": "text"
      },
      "source": [
        "What are the ratings?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2xa1MosqW0H",
        "colab_type": "code",
        "outputId": "59620d08-bcc1-4493-c516-6b6c8b9601cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "! sudo update-alternatives --config java"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
            "\n",
            "  Selection    Path                                            Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
            "  2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfBcet1yGTkq",
        "colab_type": "code",
        "outputId": "e768b549-febd-4a55-e46b-ffba280ac9e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Distinct values of ratings:')\n",
        "print(sorted(ratings.select('rating').distinct().rdd.map(lambda r: r[0]).collect()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distinct values of ratings:\n",
            "[0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-q5BtvLsTfa",
        "colab_type": "code",
        "outputId": "fc1b0be3-d0a2-49a9-8676-d0b9d220827e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.7.1\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==3.1.0\n",
            "astor==0.8.0\n",
            "astropy==3.0.5\n",
            "atari-py==0.1.15\n",
            "atomicwrites==1.3.0\n",
            "attrs==19.1.0\n",
            "audioread==2.1.8\n",
            "autograd==1.2\n",
            "Babel==2.7.0\n",
            "backcall==0.1.0\n",
            "backports.tempfile==1.0\n",
            "backports.weakref==1.0.post1\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.1.0\n",
            "blis==0.2.4\n",
            "bokeh==1.0.4\n",
            "boto==2.49.0\n",
            "boto3==1.9.189\n",
            "botocore==1.12.189\n",
            "Bottleneck==1.2.1\n",
            "branca==0.3.1\n",
            "bs4==0.0.1\n",
            "bz2file==0.98\n",
            "cachetools==3.1.1\n",
            "certifi==2019.6.16\n",
            "cffi==1.12.3\n",
            "chainer==5.4.0\n",
            "chardet==3.0.4\n",
            "Click==7.0\n",
            "cloudpickle==0.6.1\n",
            "cmake==3.12.0\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.1.3\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.14.6\n",
            "cupy-cuda100==5.4.0\n",
            "cvxopt==1.2.3\n",
            "cvxpy==1.0.15\n",
            "cycler==0.10.0\n",
            "cymem==2.0.2\n",
            "Cython==0.29.12\n",
            "daft==0.0.4\n",
            "dask==1.1.5\n",
            "dataclasses==0.6\n",
            "datascience==0.10.6\n",
            "decorator==4.4.0\n",
            "defusedxml==0.6.0\n",
            "descartes==1.1.0\n",
            "dill==0.3.0\n",
            "distributed==1.25.3\n",
            "Django==2.2.3\n",
            "dlib==19.16.0\n",
            "dm-sonnet==1.34\n",
            "docopt==0.6.2\n",
            "docutils==0.14\n",
            "dopamine-rl==1.0.5\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.1.0\n",
            "entrypoints==0.3\n",
            "ephem==3.7.6.0\n",
            "et-xmlfile==1.0.1\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.55\n",
            "fastcache==1.1.0\n",
            "fastdtw==0.3.2\n",
            "fastprogress==0.1.21\n",
            "fastrlock==0.4\n",
            "fbprophet==0.5\n",
            "feather-format==0.4.0\n",
            "featuretools==0.4.1\n",
            "filelock==3.0.12\n",
            "findspark==1.3.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.1\n",
            "folium==0.8.3\n",
            "fsspec==0.3.2\n",
            "future==0.16.0\n",
            "gast==0.2.2\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.49\n",
            "geopy==1.17.0\n",
            "gevent==1.4.0\n",
            "gin-config==0.2.0\n",
            "glob2==0.7\n",
            "google==2.0.2\n",
            "google-api-core==1.13.0\n",
            "google-api-python-client==1.7.9\n",
            "google-auth==1.4.2\n",
            "google-auth-httplib2==0.0.3\n",
            "google-auth-oauthlib==0.4.0\n",
            "google-cloud-bigquery==1.14.0\n",
            "google-cloud-core==1.0.2\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.16.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.1.7\n",
            "google-resumable-media==0.3.2\n",
            "googleapis-common-protos==1.6.0\n",
            "googledrivedownloader==0.4\n",
            "graph-nets==1.0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==0.4.15\n",
            "grpcio==1.15.0\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.2\n",
            "gunicorn==19.9.0\n",
            "gym==0.10.11\n",
            "h5py==2.8.0\n",
            "HeapDict==1.0.0\n",
            "holidays==0.9.10\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.16\n",
            "httplib2==0.11.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.8\n",
            "image==1.5.27\n",
            "imageio==2.4.1\n",
            "imagesize==1.1.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==0.18\n",
            "imutils==0.5.2\n",
            "inflect==2.1.0\n",
            "intel-openmp==2019.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.6.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.5.0\n",
            "itsdangerous==1.1.0\n",
            "jdcal==1.4.1\n",
            "jedi==0.14.1\n",
            "jieba==0.39\n",
            "Jinja2==2.10.1\n",
            "jmespath==0.9.4\n",
            "joblib==0.13.2\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.1\n",
            "jupyter-console==6.0.0\n",
            "jupyter-core==4.5.0\n",
            "kaggle==1.5.4\n",
            "kapre==0.1.3.1\n",
            "Keras==2.2.4\n",
            "Keras-Applications==1.0.8\n",
            "Keras-Preprocessing==1.1.0\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.1.0\n",
            "knnimpute==0.1.0\n",
            "librosa==0.6.3\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.29.0\n",
            "lmdb==0.96\n",
            "lucid==0.3.8\n",
            "lunardate==0.2.0\n",
            "lxml==4.2.6\n",
            "magenta==0.3.19\n",
            "Markdown==3.1.1\n",
            "MarkupSafe==1.1.1\n",
            "matplotlib==3.0.3\n",
            "matplotlib-venn==0.11.5\n",
            "mesh-tensorflow==0.0.5\n",
            "mido==1.2.6\n",
            "mir-eval==0.5\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.5.4\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==7.1.0\n",
            "moviepy==0.2.3.5\n",
            "mpi4py==3.0.2\n",
            "mpmath==1.1.0\n",
            "msgpack==0.5.6\n",
            "multiprocess==0.70.8\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.2\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbconvert==5.5.0\n",
            "nbformat==4.4.0\n",
            "networkx==2.3\n",
            "nibabel==2.3.3\n",
            "nltk==3.2.5\n",
            "nose==1.3.7\n",
            "notebook==5.2.2\n",
            "np-utils==0.5.10.0\n",
            "numba==0.40.1\n",
            "numexpr==2.6.9\n",
            "numpy==1.16.4\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.0.2\n",
            "okgrade==0.4.3\n",
            "olefile==0.46\n",
            "opencv-contrib-python==3.4.3.18\n",
            "opencv-python==3.4.5.20\n",
            "openpyxl==2.5.9\n",
            "osqp==0.5.0\n",
            "packaging==19.0\n",
            "palettable==3.2.0\n",
            "pandas==0.24.2\n",
            "pandas-datareader==0.7.0\n",
            "pandas-gbq==0.4.1\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.2\n",
            "parso==0.5.1\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.7.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==4.3.0\n",
            "pip-tools==3.9.0\n",
            "plac==0.9.6\n",
            "plotly==3.6.1\n",
            "plotnine==0.5.1\n",
            "pluggy==0.7.1\n",
            "portpicker==1.2.0\n",
            "prefetch-generator==1.0.1\n",
            "preshed==2.0.1\n",
            "pretty-midi==0.2.8\n",
            "prettytable==0.7.2\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.7.1\n",
            "promise==2.2.1\n",
            "prompt-toolkit==1.0.16\n",
            "protobuf==3.7.1\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.6.0\n",
            "py==1.8.0\n",
            "py4j==0.10.7\n",
            "pyarrow==0.14.0\n",
            "pyasn1==0.4.5\n",
            "pyasn1-modules==0.2.5\n",
            "pycocotools==2.0.0\n",
            "pycparser==2.19\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "pyemd==0.5.1\n",
            "pyglet==1.4.1\n",
            "Pygments==2.1.3\n",
            "pygobject==3.26.1\n",
            "pymc3==3.7\n",
            "pymongo==3.8.0\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.0\n",
            "pyparsing==2.4.0\n",
            "pyrsistent==0.15.3\n",
            "pysndfile==1.3.3\n",
            "PySocks==1.7.0\n",
            "pyspark==2.4.3\n",
            "pystan==2.19.0.0\n",
            "pytest==3.6.4\n",
            "python-apt==1.6.4\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.5.3\n",
            "python-louvain==0.13\n",
            "python-rtmidi==1.3.0\n",
            "python-slugify==3.0.2\n",
            "python-utils==2.3.0\n",
            "pytz==2018.9\n",
            "PyWavelets==1.0.3\n",
            "PyYAML==3.13\n",
            "pyzmq==17.0.0\n",
            "qtconsole==4.5.1\n",
            "requests==2.21.0\n",
            "requests-oauthlib==1.2.0\n",
            "resampy==0.2.1\n",
            "retrying==1.3.3\n",
            "rpy2==2.9.5\n",
            "rsa==4.0\n",
            "s3fs==0.3.0\n",
            "s3transfer==0.2.1\n",
            "scikit-image==0.15.0\n",
            "scikit-learn==0.21.2\n",
            "scipy==1.3.0\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.1.post2\n",
            "seaborn==0.9.0\n",
            "semantic-version==2.6.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.6.4.post2\n",
            "simplegeneric==0.8.1\n",
            "six==1.12.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==1.8.4\n",
            "snowballstemmer==1.9.0\n",
            "sortedcontainers==2.1.0\n",
            "spacy==2.1.6\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-websupport==1.1.2\n",
            "SQLAlchemy==1.3.5\n",
            "sqlparse==0.3.0\n",
            "srsly==0.0.7\n",
            "stable-baselines==2.2.1\n",
            "statsmodels==0.10.0\n",
            "sympy==1.1.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.3\n",
            "tblib==1.4.0\n",
            "tensor2tensor==1.11.0\n",
            "tensorboard==1.14.0\n",
            "tensorboardcolab==0.0.22\n",
            "tensorflow==1.14.0\n",
            "tensorflow-estimator==1.14.0\n",
            "tensorflow-hub==0.5.0\n",
            "tensorflow-metadata==0.14.0\n",
            "tensorflow-probability==0.7.0\n",
            "termcolor==1.1.0\n",
            "terminado==0.8.2\n",
            "testpath==0.4.2\n",
            "text-unidecode==1.2\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "tfds-nightly==1.0.2.dev201907170105\n",
            "tflearn==0.3.2\n",
            "Theano==1.0.4\n",
            "thinc==7.0.8\n",
            "toolz==0.10.0\n",
            "torch==1.1.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.3.0\n",
            "tornado==4.5.3\n",
            "tqdm==4.28.1\n",
            "traitlets==4.3.2\n",
            "tweepy==3.6.0\n",
            "typing==3.7.4\n",
            "tzlocal==1.5.1\n",
            "umap-learn==0.3.9\n",
            "uritemplate==3.0.0\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.7.0\n",
            "wasabi==0.2.2\n",
            "wcwidth==0.1.7\n",
            "webencodings==0.5.1\n",
            "Werkzeug==0.15.5\n",
            "widgetsnbextension==3.5.0\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.11.2\n",
            "xarray==0.11.3\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==1.0.0\n",
            "zipp==0.5.2\n",
            "zmq==0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivxsLAp_mJoa",
        "colab_type": "code",
        "outputId": "d84ded34-fc3a-4caa-a9c2-6d01bcc2d296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!echo $JAVA_HOME"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTBrHV4_3MLP",
        "colab_type": "text"
      },
      "source": [
        "What is minimum number of ratings per user and minimum number of ratings per movie?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_DHeAUp3MLQ",
        "colab_type": "code",
        "outputId": "c457ff94-eed9-4096-f439-8a52bfb5d02f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "tmp1 = ratings.groupBy(\"userID\").count().toPandas()['count'].min()\n",
        "tmp2 = ratings.groupBy(\"movieId\").count().toPandas()['count'].min()\n",
        "print('For the users that rated movies and the movies that were rated:')\n",
        "print('Minimum number of ratings per user is {}'.format(tmp1))\n",
        "print('Minimum number of ratings per movie is {}'.format(tmp2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the users that rated movies and the movies that were rated:\n",
            "Minimum number of ratings per user is 20\n",
            "Minimum number of ratings per movie is 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiHEOcb73MLX",
        "colab_type": "text"
      },
      "source": [
        "How many movies are rated by only one user?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzY9DlWd3MLZ",
        "colab_type": "code",
        "outputId": "ad016ac6-674f-48b3-f6ba-18ab026d9f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tmp1 = sum(ratings.groupBy(\"movieId\").count().toPandas()['count'] == 1)\n",
        "tmp2 = ratings.select('movieId').distinct().count()\n",
        "print('{} out of {} movies are rated by only one user'.format(tmp1, tmp2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3972 out of 26744 movies are rated by only one user\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eZpJO6I3MLh",
        "colab_type": "text"
      },
      "source": [
        "What is the total number of users in the data sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH209Lrb3MLj",
        "colab_type": "code",
        "outputId": "a323c18b-36ce-41db-a72d-a304adef2182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tmp = ratings.select('userID').distinct().count()\n",
        "print('We have a total of {} distinct users in the data sets'.format(tmp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have a total of 138493 distinct users in the data sets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBjMLL5x3MLq",
        "colab_type": "text"
      },
      "source": [
        "What is the total number of movies in the data sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYdEoMqs3MLt",
        "colab_type": "code",
        "outputId": "c43c952b-db63-4c18-85c8-0c1940a1dd95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tmp = movies.select('movieID').distinct().count()\n",
        "print('We have a total of {} distinct movies in the data sets'.format(tmp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have a total of 27278 distinct movies in the data sets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQUUR7N3ML0",
        "colab_type": "text"
      },
      "source": [
        "How many movies are rated by users? List movies not rated yet?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W83f7CIY3ML1",
        "colab_type": "code",
        "outputId": "c2ee6eb9-b08d-47ec-f3a1-deba8eb82109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tmp1 = movies.select('movieID').distinct().count()\n",
        "tmp2 = ratings.select('movieID').distinct().count()\n",
        "print('We have a total of {} distinct movies that are rated by users in ratings table'.format(tmp2))\n",
        "print('We have {} movies that are not rated yet'.format(tmp1-tmp2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have a total of 26744 distinct movies that are rated by users in ratings table\n",
            "We have 534 movies that are not rated yet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpjY0-UK3ML-",
        "colab_type": "code",
        "outputId": "880cc2a4-b0a4-4a2c-d128-155d433d52c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# create a temp SQL table view for easier query\n",
        "movies.createOrReplaceTempView(\"movies\")\n",
        "ratings.createOrReplaceTempView(\"ratings\")\n",
        "print('List movies that are not rated yet: ')\n",
        "# SQL query (NOTE: WHERE ... NOT IN ... == ... LEFT JOIN ... WHERE ... IS NULL)\n",
        "# Approach 1\n",
        "spark.sql(\n",
        "    \"SELECT movieId, title \"\n",
        "    \"FROM movies \"\n",
        "    \"WHERE movieId NOT IN (SELECT distinct(movieId) FROM ratings)\"\n",
        ").show(10)\n",
        "# Approach 2\n",
        "# spark.sql(\n",
        "#     \"SELECT m.movieId, m.title \"\n",
        "#     \"FROM movies m LEFT JOIN ratings r ON m.movieId=r.movieId \"\n",
        "#     \"WHERE r.movieId IS NULL\"\n",
        "# ).show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List movies that are not rated yet: \n",
            "+-------+--------------------+\n",
            "|movieId|               title|\n",
            "+-------+--------------------+\n",
            "|  26018|Chase a Crooked S...|\n",
            "|  26580|Park Is Mine, The...|\n",
            "|  27249|Trumpet of the Sw...|\n",
            "|  27396|Gentleman's Game,...|\n",
            "|  31797|White Banners (1938)|\n",
            "|  32773|Parenti serpenti ...|\n",
            "|  33019|Barefoot (Barfuss...|\n",
            "|  33229|Angry Silence, Th...|\n",
            "|  33573|Wu Tang Master (T...|\n",
            "|  45994|National Lampoon'...|\n",
            "+-------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da3P7Wn13MMF",
        "colab_type": "text"
      },
      "source": [
        "List all movie genres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOZ3xvWw3MMG",
        "colab_type": "code",
        "outputId": "41f06afa-d9f6-4d89-9663-a5593412c208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# define a udf for splitting the genres string\n",
        "splitter = UserDefinedFunction(lambda x: x.split('|'), ArrayType(StringType()))\n",
        "# query\n",
        "print('All distinct genres: ')\n",
        "movies.select(explode(splitter(\"genres\")).alias(\"genres\")).distinct().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All distinct genres: \n",
            "+------------------+\n",
            "|            genres|\n",
            "+------------------+\n",
            "|             Crime|\n",
            "|           Romance|\n",
            "|          Thriller|\n",
            "|         Adventure|\n",
            "|             Drama|\n",
            "|               War|\n",
            "|       Documentary|\n",
            "|           Fantasy|\n",
            "|           Mystery|\n",
            "|           Musical|\n",
            "|         Animation|\n",
            "|         Film-Noir|\n",
            "|(no genres listed)|\n",
            "|              IMAX|\n",
            "|            Horror|\n",
            "|           Western|\n",
            "|            Comedy|\n",
            "|          Children|\n",
            "|            Action|\n",
            "|            Sci-Fi|\n",
            "+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-wrYTwx3MML",
        "colab_type": "text"
      },
      "source": [
        "Find out the number of movies for each category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kiJuIsp3MMM",
        "colab_type": "code",
        "outputId": "3b1d315e-ab0e-4925-f365-b4b265e85251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "print('Counts of movies per genre')\n",
        "movies.select('movieID', explode(splitter(\"genres\")).alias(\"genres\")) \\\n",
        "    .groupby('genres') \\\n",
        "    .count() \\\n",
        "    .sort(desc('count')) \\\n",
        "    .show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counts of movies per genre\n",
            "+------------------+-----+\n",
            "|            genres|count|\n",
            "+------------------+-----+\n",
            "|             Drama|13344|\n",
            "|            Comedy| 8374|\n",
            "|          Thriller| 4178|\n",
            "|           Romance| 4127|\n",
            "|            Action| 3520|\n",
            "|             Crime| 2939|\n",
            "|            Horror| 2611|\n",
            "|       Documentary| 2471|\n",
            "|         Adventure| 2329|\n",
            "|            Sci-Fi| 1743|\n",
            "|           Mystery| 1514|\n",
            "|           Fantasy| 1412|\n",
            "|               War| 1194|\n",
            "|          Children| 1139|\n",
            "|           Musical| 1036|\n",
            "|         Animation| 1027|\n",
            "|           Western|  676|\n",
            "|         Film-Noir|  330|\n",
            "|(no genres listed)|  246|\n",
            "|              IMAX|  196|\n",
            "+------------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzsNeLxG3MMR",
        "colab_type": "text"
      },
      "source": [
        "## Spark ALS based approach for training model\n",
        "1. Reload data\n",
        "2. Split data into train, validation, test\n",
        "3. ALS model selection and evaluation\n",
        "4. Model testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuwD8TsO3MMS",
        "colab_type": "text"
      },
      "source": [
        "### Reload data\n",
        "We will use an RDD-based API from pyspark.mllib to predict the ratings, so let's reload \"ratings.csv\" using sc.textFile and then convert it to the form of (user, item, rating) tuples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPRu7UVV3MMT",
        "colab_type": "code",
        "outputId": "fda09bd3-955c-49e5-a48f-9f5a9aeb676b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load data\n",
        "movie_rating = sc.textFile(os.path.join('/content/ml-latest-small', 'ratings.csv'))\n",
        "# preprocess data -- only need [\"userId\", \"movieId\", \"rating\"]\n",
        "header = movie_rating.take(1)[0]\n",
        "rating_data = movie_rating \\\n",
        "    .filter(lambda line: line!=header) \\\n",
        "    .map(lambda line: line.split(\",\")) \\\n",
        "    .map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2]))) \\\n",
        "    .cache()\n",
        "# check three rows\n",
        "rating_data.take(3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1, 4.0), (1, 3, 4.0), (1, 6, 4.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWkpsVGc3MMZ",
        "colab_type": "text"
      },
      "source": [
        "### Split data\n",
        "Now we split the data into training/validation/testing sets using a 6/2/2 ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbddrdia3MMb",
        "colab_type": "code",
        "outputId": "735ea2ba-6e6a-4f84-e003-16e914f4d3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train, validation, test = rating_data.randomSplit([7, 1, 2], seed=99)\n",
        "# cache data\n",
        "train.cache()\n",
        "validation.cache()\n",
        "test.cache()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[48] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXQmL9-O3MMf",
        "colab_type": "text"
      },
      "source": [
        "### ALS model selection and evaluation\n",
        "With the ALS model, we can use a grid search to find the optimal hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEGcyvPt3MMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_ALS(train_data, validation_data, num_iters, reg_param, ranks):\n",
        "    \"\"\"\n",
        "    Grid Search Function to select the best model based on RMSE of hold-out data\n",
        "    \"\"\"\n",
        "    # initial\n",
        "    min_error = float('inf')\n",
        "    best_rank = -1\n",
        "    best_regularization = 0\n",
        "    best_model = None\n",
        "    for rank in ranks:\n",
        "        for reg in reg_param:\n",
        "            # train ALS model\n",
        "            model = ALS.train(\n",
        "                ratings=train_data,    # (userID, productID, rating) tuple\n",
        "                iterations=num_iters,\n",
        "                rank=rank,\n",
        "                lambda_=reg,           # regularization param\n",
        "                seed=99)\n",
        "            # make prediction\n",
        "            valid_data = validation_data.map(lambda p: (p[0], p[1]))\n",
        "            predictions = model.predictAll(valid_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "            # get the rating result\n",
        "            ratesAndPreds = validation_data.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
        "            # get the RMSE\n",
        "            MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
        "            error = math.sqrt(MSE)\n",
        "            print('{} latent factors and regularization = {}: validation RMSE is {}'.format(rank, reg, error))\n",
        "            if error < min_error:\n",
        "                min_error = error\n",
        "                best_rank = rank\n",
        "                best_regularization = reg\n",
        "                best_model = model\n",
        "    print('\\nThe best model has {} latent factors and regularization = {}'.format(best_rank, best_regularization))\n",
        "    return best_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qhOkwvb3MMj",
        "colab_type": "code",
        "outputId": "d0fe2aab-2a66-449f-cab3-5765aa118cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "# hyper-param config\n",
        "num_iterations = 10\n",
        "ranks = [8, 10, 12, 14, 16, 18, 20]\n",
        "reg_params = [0.01, 0.05, 0.1, 0.2]\n",
        "\n",
        "# grid search and select best model\n",
        "start_time = time.time()\n",
        "final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
        "\n",
        "print ('Total Runtime: {:.2f} seconds'.format(time.time() - start_time))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 latent factors and regularization = 0.01: validation RMSE is 1.1017008447839858\n",
            "8 latent factors and regularization = 0.05: validation RMSE is 0.9534044223915731\n",
            "8 latent factors and regularization = 0.1: validation RMSE is 0.8944069717395818\n",
            "8 latent factors and regularization = 0.2: validation RMSE is 0.8824989786280941\n",
            "10 latent factors and regularization = 0.01: validation RMSE is 1.1618423518507266\n",
            "10 latent factors and regularization = 0.05: validation RMSE is 0.9787187338228882\n",
            "10 latent factors and regularization = 0.1: validation RMSE is 0.8981742170998336\n",
            "10 latent factors and regularization = 0.2: validation RMSE is 0.8823926323306295\n",
            "12 latent factors and regularization = 0.01: validation RMSE is 1.181572581327799\n",
            "12 latent factors and regularization = 0.05: validation RMSE is 0.9686110975320976\n",
            "12 latent factors and regularization = 0.1: validation RMSE is 0.893549285068245\n",
            "12 latent factors and regularization = 0.2: validation RMSE is 0.883037369789155\n",
            "14 latent factors and regularization = 0.01: validation RMSE is 1.2173842463018634\n",
            "14 latent factors and regularization = 0.05: validation RMSE is 0.9802699122063308\n",
            "14 latent factors and regularization = 0.1: validation RMSE is 0.8938893976302362\n",
            "14 latent factors and regularization = 0.2: validation RMSE is 0.8821208461876872\n",
            "16 latent factors and regularization = 0.01: validation RMSE is 1.2311336940525106\n",
            "16 latent factors and regularization = 0.05: validation RMSE is 0.9799925254129503\n",
            "16 latent factors and regularization = 0.1: validation RMSE is 0.8960913287448063\n",
            "16 latent factors and regularization = 0.2: validation RMSE is 0.8838004248932719\n",
            "18 latent factors and regularization = 0.01: validation RMSE is 1.2892981447563976\n",
            "18 latent factors and regularization = 0.05: validation RMSE is 0.9916101723655052\n",
            "18 latent factors and regularization = 0.1: validation RMSE is 0.9000931216213914\n",
            "18 latent factors and regularization = 0.2: validation RMSE is 0.8850695696410472\n",
            "20 latent factors and regularization = 0.01: validation RMSE is 1.2713312879299141\n",
            "20 latent factors and regularization = 0.05: validation RMSE is 0.9841793461114287\n",
            "20 latent factors and regularization = 0.1: validation RMSE is 0.893898593350339\n",
            "20 latent factors and regularization = 0.2: validation RMSE is 0.884553897348736\n",
            "\n",
            "The best model has 14 latent factors and regularization = 0.2\n",
            "Total Runtime: 197.57 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHo-5TU53MMo",
        "colab_type": "text"
      },
      "source": [
        "### ALS model learning curve\n",
        "As we increase number of iterations in training ALS, we can see how RMSE changes and whether or not model is overfitted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q2jEdL53MMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_learning_curve(arr_iters, train_data, validation_data, reg, rank):\n",
        "    \"\"\"\n",
        "    Plot function to show learning curve of ALS\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    for num_iters in arr_iters:\n",
        "        # train ALS model\n",
        "        model = ALS.train(\n",
        "            ratings=train_data,    # (userID, productID, rating) tuple\n",
        "            iterations=num_iters,\n",
        "            rank=rank,\n",
        "            lambda_=reg,           # regularization param\n",
        "            seed=99)\n",
        "        # make prediction\n",
        "        valid_data = validation_data.map(lambda p: (p[0], p[1]))\n",
        "        predictions = model.predictAll(valid_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "        # get the rating result\n",
        "        ratesAndPreds = validation_data.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
        "        # get the RMSE\n",
        "        MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
        "        error = math.sqrt(MSE)\n",
        "        # add to errors\n",
        "        errors.append(error)\n",
        "\n",
        "    # plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(arr_iters, errors)\n",
        "    plt.xlabel('number of iterations')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title('ALS Learning Curve')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uhrbSUW3MMt",
        "colab_type": "code",
        "outputId": "9acc6585-6e46-4c9c-ddb4-373660328e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "# create an array of num_iters\n",
        "iter_array = list(range(1, 11))\n",
        "# create learning curve plot\n",
        "plot_learning_curve(iter_array, train, validation, 0.05, 20)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAGDCAYAAAAVh7eRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEvz/XKnmXv1tWa4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDWepL4d3MMx",
        "colab_type": "text"
      },
      "source": [
        "After 3 iterations, alternating gradient descend starts to converge at an error around 0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An1EeQZC3MMx",
        "colab_type": "text"
      },
      "source": [
        "### Model testing\n",
        "And finally, make a prediction and check the testing error using out-of-sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8bUoHZl3MMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "80693b5a-fa22-4a87-d65d-a55e8653b7ba"
      },
      "source": [
        "# make prediction using test data\n",
        "test_data = test.map(lambda p: (p[0], p[1]))\n",
        "predictions = final_model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "# get the rating result\n",
        "ratesAndPreds = test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
        "# get the RMSE\n",
        "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
        "error = math.sqrt(MSE)\n",
        "print('The out-of-sample RMSE of rating predictions is', round(error, 4))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The out-of-sample RMSE of rating predictions is 0.8921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weyPAayA3MM1",
        "colab_type": "text"
      },
      "source": [
        "### Make movie recommendation to myself\n",
        "We need to define a function that takes new user's movie rating and output top 10 recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ehbg3Qh3MM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_movieId(df_movies, fav_movie_list):\n",
        "    \"\"\"\n",
        "    return all movieId(s) of user's favorite movies\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    df_movies: spark Dataframe, movies data\n",
        "    \n",
        "    fav_movie_list: list, user's list of favorite movies\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    movieId_list: list of movieId(s)\n",
        "    \"\"\"\n",
        "    movieId_list = []\n",
        "    for movie in fav_movie_list:\n",
        "        movieIds = df_movies \\\n",
        "            .filter(movies.title.like('%{}%'.format(movie))) \\\n",
        "            .select('movieId') \\\n",
        "            .rdd \\\n",
        "            .map(lambda r: r[0]) \\\n",
        "            .collect()\n",
        "        movieId_list.extend(movieIds)\n",
        "    return list(set(movieId_list))\n",
        "\n",
        "\n",
        "def add_new_user_to_data(train_data, movieId_list, spark_context):\n",
        "    \"\"\"\n",
        "    add new rows with new user, user's movie and ratings to\n",
        "    existing train data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_data: spark RDD, ratings data\n",
        "    \n",
        "    movieId_list: list, list of movieId(s)\n",
        "\n",
        "    spark_context: Spark Context object\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    new train data with the new user's rows\n",
        "    \"\"\"\n",
        "    # get new user id\n",
        "    new_id = train_data.map(lambda r: r[0]).max() + 1\n",
        "    # get max rating\n",
        "    max_rating = train_data.map(lambda r: r[2]).max()\n",
        "    # create new user rdd\n",
        "    user_rows = [(new_id, movieId, max_rating) for movieId in movieId_list]\n",
        "    new_rdd = spark_context.parallelize(user_rows)\n",
        "    # return new train data\n",
        "    return train_data.union(new_rdd)\n",
        "\n",
        "\n",
        "def get_inference_data(train_data, df_movies, movieId_list):\n",
        "    \"\"\"\n",
        "    return a rdd with the userid and all movies (except ones in movieId_list)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_data: spark RDD, ratings data\n",
        "\n",
        "    df_movies: spark Dataframe, movies data\n",
        "    \n",
        "    movieId_list: list, list of movieId(s)\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    inference data: Spark RDD\n",
        "    \"\"\"\n",
        "    # get new user id\n",
        "    new_id = train_data.map(lambda r: r[0]).max() + 1\n",
        "    # return inference rdd\n",
        "    return df_movies.rdd \\\n",
        "        .map(lambda r: r[0]) \\\n",
        "        .distinct() \\\n",
        "        .filter(lambda x: x not in movieId_list) \\\n",
        "        .map(lambda x: (new_id, x))\n",
        "\n",
        "\n",
        "def make_recommendation(best_model_params, ratings_data, df_movies, \n",
        "                        fav_movie_list, n_recommendations, spark_context):\n",
        "    \"\"\"\n",
        "    return top n movie recommendation based on user's input list of favorite movies\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    best_model_params: dict, {'iterations': iter, 'rank': rank, 'lambda_': reg}\n",
        "\n",
        "    ratings_data: spark RDD, ratings data\n",
        "\n",
        "    df_movies: spark Dataframe, movies data\n",
        "\n",
        "    fav_movie_list: list, user's list of favorite movies\n",
        "\n",
        "    n_recommendations: int, top n recommendations\n",
        "\n",
        "    spark_context: Spark Context object\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    list of top n movie recommendations\n",
        "    \"\"\"\n",
        "    # modify train data by adding new user's rows\n",
        "    movieId_list = get_movieId(df_movies, fav_movie_list)\n",
        "    train_data = add_new_user_to_data(ratings_data, movieId_list, spark_context)\n",
        "    \n",
        "    # train best ALS\n",
        "    model = ALS.train(\n",
        "        ratings=train_data,\n",
        "        iterations=best_model_params.get('iterations', None),\n",
        "        rank=best_model_params.get('rank', None),\n",
        "        lambda_=best_model_params.get('lambda_', None),\n",
        "        seed=99)\n",
        "    \n",
        "    # get inference rdd\n",
        "    inference_rdd = get_inference_data(ratings_data, df_movies, movieId_list)\n",
        "    \n",
        "    # inference\n",
        "    predictions = model.predictAll(inference_rdd).map(lambda r: (r[1], r[2]))\n",
        "    \n",
        "    # get top n movieId\n",
        "    topn_rows = predictions.sortBy(lambda r: r[1], ascending=False).take(n_recommendations)\n",
        "    topn_ids = [r[0] for r in topn_rows]\n",
        "    \n",
        "    # return movie titles\n",
        "    return df_movies.filter(movies.movieId.isin(topn_ids)) \\\n",
        "                    .select('title') \\\n",
        "                    .rdd \\\n",
        "                    .map(lambda r: r[0]) \\\n",
        "                    .collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBvzCd7E3MM4",
        "colab_type": "text"
      },
      "source": [
        "Let's pretend I am a new user in this recommender system. I will input a handful of my all-time favorite movies into the system. And then the system should output top N movie recommendations for me to watch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhnQ341u3MM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "ebb57a63-bfe4-4b22-acca-e3257b527e85"
      },
      "source": [
        "# my favorite movies\n",
        "my_favorite_movies = ['Toy Story']\n",
        "\n",
        "# get recommends\n",
        "recommends = make_recommendation(\n",
        "    best_model_params={'iterations': 10, 'rank': 20, 'lambda_': 0.05}, \n",
        "    ratings_data=rating_data, \n",
        "    df_movies=movies, \n",
        "    fav_movie_list=my_favorite_movies, \n",
        "    n_recommendations=15, \n",
        "    spark_context=sc)\n",
        "\n",
        "print('Recommendations for {}:'.format(my_favorite_movies[0]))\n",
        "for i, title in enumerate(recommends):\n",
        "    print('{0}: {1}'.format(i+1, title))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recommendations for Toy Story:\n",
            "1: Hoop Dreams (1994)\n",
            "2: Shawshank Redemption, The (1994)\n",
            "3: Silence of the Lambs, The (1991)\n",
            "4: Wallace & Gromit: The Best of Aardman Animation (1996)\n",
            "5: Philadelphia Story, The (1940)\n",
            "6: It Happened One Night (1934)\n",
            "7: It's a Wonderful Life (1946)\n",
            "8: Wallace & Gromit: The Wrong Trousers (1993)\n",
            "9: Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
            "10: Good, the Bad and the Ugly, The (Buono, il brutto, il cattivo, Il) (1966)\n",
            "11: 12 Angry Men (1957)\n",
            "12: Amadeus (1984)\n",
            "13: Fantasia (1940)\n",
            "14: General, The (1926)\n",
            "15: Yojimbo (1961)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVP25Xs23MM-",
        "colab_type": "text"
      },
      "source": [
        "This list of movie recommendations look completely different than the list from my previous **KNN** model recommender. Not only it recommends movies outside of years between 2007 and 2009 periods, but also recommends movies that were less known. So this can offer users some elements of suprise so that users won't get bored by getting the same popular movies all the time.\n",
        "\n",
        "So this list of recommendations can be blended into the previous list of recommendations from **KNN** model recommender"
      ]
    }
  ]
}